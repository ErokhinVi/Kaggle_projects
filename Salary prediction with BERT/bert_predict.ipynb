{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92b20cee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-13T20:58:37.763330Z",
     "iopub.status.busy": "2023-01-13T20:58:37.762545Z",
     "iopub.status.idle": "2023-01-13T20:58:48.219237Z",
     "shell.execute_reply": "2023-01-13T20:58:48.217916Z",
     "shell.execute_reply.started": "2023-01-13T20:58:37.763234Z"
    },
    "id": "n7h6P22uDuiI"
   },
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install nona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a64f2e2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-13T20:58:48.222439Z",
     "iopub.status.busy": "2023-01-13T20:58:48.221999Z",
     "iopub.status.idle": "2023-01-13T20:58:48.237327Z",
     "shell.execute_reply": "2023-01-13T20:58:48.236142Z",
     "shell.execute_reply.started": "2023-01-13T20:58:48.222391Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/df-salary/train_rev1.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0209b591",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-13T20:58:48.239746Z",
     "iopub.status.busy": "2023-01-13T20:58:48.239359Z",
     "iopub.status.idle": "2023-01-13T20:58:57.070667Z",
     "shell.execute_reply": "2023-01-13T20:58:57.069542Z",
     "shell.execute_reply.started": "2023-01-13T20:58:48.239710Z"
    },
    "id": "c859605a"
   },
   "outputs": [],
   "source": [
    "import torch, gc, random\n",
    "from transformers.file_utils import is_tf_available, is_torch_available\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "# %load_ext memory_profiler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import re\n",
    "from nona.nona import nona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "951801d0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-01-13T20:58:57.075662Z",
     "iopub.status.busy": "2023-01-13T20:58:57.074123Z",
     "iopub.status.idle": "2023-01-13T20:58:57.157520Z",
     "shell.execute_reply": "2023-01-13T20:58:57.156362Z",
     "shell.execute_reply.started": "2023-01-13T20:58:57.075600Z"
    },
    "id": "jiBzj-5tDnvO",
    "outputId": "c9c47f4d-34fd-4c1d-85c5-984e8b904cab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jan 13 20:58:57 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.82.01    Driver Version: 470.82.01    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   38C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6fdf90d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-13T20:58:57.159534Z",
     "iopub.status.busy": "2023-01-13T20:58:57.159160Z",
     "iopub.status.idle": "2023-01-13T20:58:57.164502Z",
     "shell.execute_reply": "2023-01-13T20:58:57.163434Z",
     "shell.execute_reply.started": "2023-01-13T20:58:57.159493Z"
    },
    "id": "3Hs5LwoFFV-1"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b34bb5ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-13T20:58:57.166991Z",
     "iopub.status.busy": "2023-01-13T20:58:57.165936Z",
     "iopub.status.idle": "2023-01-13T20:59:06.862973Z",
     "shell.execute_reply": "2023-01-13T20:59:06.861930Z",
     "shell.execute_reply.started": "2023-01-13T20:58:57.166955Z"
    },
    "id": "566eca83"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/df-salary/train_rev1.csv')\n",
    "df = df.sample(200000,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "398e385a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-13T20:59:06.865390Z",
     "iopub.status.busy": "2023-01-13T20:59:06.865042Z",
     "iopub.status.idle": "2023-01-13T20:59:06.931362Z",
     "shell.execute_reply": "2023-01-13T20:59:06.930376Z",
     "shell.execute_reply.started": "2023-01-13T20:59:06.865361Z"
    }
   },
   "outputs": [],
   "source": [
    "df.drop('ContractType',axis=1,inplace=True)\n",
    "\n",
    "def enc_with_na(df, column):\n",
    "    enc = OneHotEncoder(sparse=False, drop='first')\n",
    "    enc.fit(df[[column]].dropna())\n",
    "    \n",
    "    return enc,pd.DataFrame(enc.transform(df[[column]].dropna(\n",
    "    )), index=df.loc[df.loc[:, column].notna()].index, columns=enc.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32e2e937",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-13T20:59:06.933578Z",
     "iopub.status.busy": "2023-01-13T20:59:06.932934Z",
     "iopub.status.idle": "2023-01-13T20:59:11.461301Z",
     "shell.execute_reply": "2023-01-13T20:59:11.460237Z",
     "shell.execute_reply.started": "2023-01-13T20:59:06.933535Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "100%|██████████| 29/29 [00:00<00:00, 1196.26it/s]\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:18: FutureWarning: The default value of regex will change from True to False in a future version.\n"
     ]
    }
   ],
   "source": [
    "ct_enc,ct_features = enc_with_na(df,'ContractTime')\n",
    "cat_enc,cat_features = enc_with_na(df,'Category')\n",
    "\n",
    "df = df.drop(['ContractTime','Category'],axis=1).join([ct_features,\n",
    "cat_features])\n",
    "\n",
    "features = df.drop(['Id','Title','FullDescription','LocationRaw','LocationNormalized','Company','SalaryRaw',\n",
    "                   'SalaryNormalized','SourceName'],axis=1)\n",
    "\n",
    "nona(data=features, algreg=make_pipeline(StandardScaler(with_mean=False), Ridge(\n",
    "    alpha=0.1)), algclass=RandomForestClassifier(max_depth=2, random_state=42))\n",
    "\n",
    "df = df.join(pd.DataFrame(ct_enc.inverse_transform(pd.DataFrame(\n",
    "    features.loc[:, 'x0_permanent'])), index=df.index, columns=['ContractTime'])).drop(ct_enc.get_feature_names(), axis=1)\n",
    "df = df.join(pd.DataFrame(cat_enc.inverse_transform(pd.DataFrame(\n",
    "    features.drop('x0_permanent',axis=1))), index=df.index, columns=['Category'])).drop(cat_enc.get_feature_names(), axis=1)\n",
    "\n",
    "df[\"FullDescription\"] = df[\"FullDescription\"].str.replace(r'https?://[^\\s<>\"]+|www\\.[^\\s<>\"]+', \"\")\n",
    "\n",
    "df.FullDescription = 'Contract time for this vacancy is '+ df.ContractTime+'. ' + df.FullDescription\n",
    "df.FullDescription = 'The category for this job is '+ df.Category+'. ' + df.FullDescription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0b443f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-13T20:59:11.463272Z",
     "iopub.status.busy": "2023-01-13T20:59:11.462880Z",
     "iopub.status.idle": "2023-01-13T20:59:11.471213Z",
     "shell.execute_reply": "2023-01-13T20:59:11.470202Z",
     "shell.execute_reply.started": "2023-01-13T20:59:11.463230Z"
    },
    "id": "f0607805"
   },
   "outputs": [],
   "source": [
    "max_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ad7597a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-13T20:59:11.475696Z",
     "iopub.status.busy": "2023-01-13T20:59:11.475096Z",
     "iopub.status.idle": "2023-01-13T21:01:51.452147Z",
     "shell.execute_reply": "2023-01-13T21:01:51.451121Z",
     "shell.execute_reply.started": "2023-01-13T20:59:11.475642Z"
    },
    "id": "49c92e20"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Make data\n",
    "X = df.FullDescription\n",
    "y = np.log1p(df.SalaryNormalized+1)\n",
    "\n",
    "\n",
    "# Split Data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X.tolist(), y, test_size=.1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=.1)\n",
    "\n",
    "# Call the Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Encode the text\n",
    "train_encodings = tokenizer(X_train, truncation=True, padding=True, max_length=max_length)\n",
    "valid_encodings = tokenizer(X_valid, truncation=True, padding=True, max_length=max_length)\n",
    "test_encodings = tokenizer(X_test, truncation=True, padding=True, max_length=max_length)\n",
    "\n",
    "\n",
    "\n",
    "class MakeTorchData(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor([self.labels[idx]])\n",
    "        item[\"labels\"] = float(item[\"labels\"])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# convert our tokenized data into a torch Dataset\n",
    "train_dataset = MakeTorchData(train_encodings, y_train.ravel())\n",
    "valid_dataset = MakeTorchData(valid_encodings, y_valid.ravel())\n",
    "test_dataset = MakeTorchData(test_encodings, y_test.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af9795e1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-01-13T21:01:51.454340Z",
     "iopub.status.busy": "2023-01-13T21:01:51.453669Z",
     "iopub.status.idle": "2023-01-13T21:02:01.383115Z",
     "shell.execute_reply": "2023-01-13T21:02:01.378806Z",
     "shell.execute_reply.started": "2023-01-13T21:01:51.454299Z"
    },
    "id": "70ad6a6b",
    "outputId": "43424b59-9044-432c-85c6-d26222c400fd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', \n",
    "                                                           num_labels = 1).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba0cfcde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-13T21:02:01.389343Z",
     "iopub.status.busy": "2023-01-13T21:02:01.388586Z",
     "iopub.status.idle": "2023-01-13T21:02:01.398062Z",
     "shell.execute_reply": "2023-01-13T21:02:01.397088Z",
     "shell.execute_reply.started": "2023-01-13T21:02:01.389301Z"
    },
    "id": "5623a753"
   },
   "outputs": [],
   "source": [
    "def compute_metrics_for_regression(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    labels = labels.reshape(-1, 1)\n",
    "\n",
    "    mse = mean_squared_error(labels, logits)\n",
    "    rmse = mean_squared_error(labels, logits, squared=False)\n",
    "    mae = mean_absolute_error(labels, logits)\n",
    "    r2 = r2_score(labels, logits)\n",
    "    smape = 1/len(labels) * np.sum(2 * np.abs(logits-labels) / (np.abs(labels) + np.abs(logits))*100)\n",
    "\n",
    "    return {\"mse\": mse, \"rmse\": rmse, \"mae\": mae, \"r2\": r2, \"smape\": smape}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12b2a813",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-13T21:02:01.400151Z",
     "iopub.status.busy": "2023-01-13T21:02:01.399615Z",
     "iopub.status.idle": "2023-01-13T21:02:01.415491Z",
     "shell.execute_reply": "2023-01-13T21:02:01.414488Z",
     "shell.execute_reply.started": "2023-01-13T21:02:01.400108Z"
    },
    "id": "cfac0b69"
   },
   "outputs": [],
   "source": [
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0de0a3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-13T21:02:01.417357Z",
     "iopub.status.busy": "2023-01-13T21:02:01.416949Z",
     "iopub.status.idle": "2023-01-13T21:02:01.426459Z",
     "shell.execute_reply": "2023-01-13T21:02:01.425431Z",
     "shell.execute_reply.started": "2023-01-13T21:02:01.417322Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f2be7ad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2023-01-13T21:02:01.428256Z",
     "iopub.status.busy": "2023-01-13T21:02:01.427814Z",
     "iopub.status.idle": "2023-01-13T23:52:10.897895Z",
     "shell.execute_reply": "2023-01-13T23:52:10.896866Z",
     "shell.execute_reply.started": "2023-01-13T21:02:01.428218Z"
    },
    "id": "babe9eed",
    "outputId": "d00adb81-190d-4ca1-9833-df0d29bef78c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "***** Running training *****\n",
      "  Num examples = 162000\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 25315\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25315' max='25315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25315/25315 2:48:49, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mse</th>\n",
       "      <th>Rmse</th>\n",
       "      <th>Mae</th>\n",
       "      <th>R2</th>\n",
       "      <th>Smape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.093000</td>\n",
       "      <td>0.083277</td>\n",
       "      <td>0.083277</td>\n",
       "      <td>0.288577</td>\n",
       "      <td>0.220120</td>\n",
       "      <td>0.653671</td>\n",
       "      <td>2.129631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.077200</td>\n",
       "      <td>0.062945</td>\n",
       "      <td>0.062945</td>\n",
       "      <td>0.250888</td>\n",
       "      <td>0.184665</td>\n",
       "      <td>0.738227</td>\n",
       "      <td>1.789336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.063400</td>\n",
       "      <td>0.058853</td>\n",
       "      <td>0.058853</td>\n",
       "      <td>0.242597</td>\n",
       "      <td>0.174391</td>\n",
       "      <td>0.755243</td>\n",
       "      <td>1.686801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.055100</td>\n",
       "      <td>0.070401</td>\n",
       "      <td>0.070401</td>\n",
       "      <td>0.265331</td>\n",
       "      <td>0.202370</td>\n",
       "      <td>0.707220</td>\n",
       "      <td>1.959186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.051000</td>\n",
       "      <td>0.059627</td>\n",
       "      <td>0.059627</td>\n",
       "      <td>0.244186</td>\n",
       "      <td>0.177942</td>\n",
       "      <td>0.752026</td>\n",
       "      <td>1.720433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 20000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to D:/checkpoint-5063\n",
      "Configuration saved in D:/checkpoint-5063/config.json\n",
      "Model weights saved in D:/checkpoint-5063/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to D:/checkpoint-10126\n",
      "Configuration saved in D:/checkpoint-10126/config.json\n",
      "Model weights saved in D:/checkpoint-10126/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to D:/checkpoint-15189\n",
      "Configuration saved in D:/checkpoint-15189/config.json\n",
      "Model weights saved in D:/checkpoint-15189/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to D:/checkpoint-20252\n",
      "Configuration saved in D:/checkpoint-20252/config.json\n",
      "Model weights saved in D:/checkpoint-20252/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20000\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to D:/checkpoint-25315\n",
      "Configuration saved in D:/checkpoint-25315/config.json\n",
      "Model weights saved in D:/checkpoint-25315/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from D:/checkpoint-5063 (score: 0.2885771691799164).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 20000\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2375' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1250/1250 02:30]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.08327678591012955,\n",
       " 'eval_mse': 0.08327678591012955,\n",
       " 'eval_rmse': 0.2885771691799164,\n",
       " 'eval_mae': 0.2201199233531952,\n",
       " 'eval_r2': 0.6536712649745798,\n",
       " 'eval_smape': 2.1296306640625002,\n",
       " 'eval_runtime': 78.1274,\n",
       " 'eval_samples_per_second': 255.992,\n",
       " 'eval_steps_per_second': 16.0,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Specifiy the arguments for the trainer  \n",
    "training_args = TrainingArguments(\n",
    "    output_dir ='D:/',          \n",
    "    num_train_epochs = num_epochs,     \n",
    "    per_device_train_batch_size = 32,   \n",
    "    per_device_eval_batch_size = 16,   \n",
    "    weight_decay = 0.01,               \n",
    "    learning_rate = 2e-5,\n",
    "    logging_dir = './logs',            \n",
    "    save_total_limit = 10,\n",
    "    load_best_model_at_end = True,     \n",
    "    metric_for_best_model = 'rmse',    \n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    optim=\"adamw_torch\"\n",
    ") \n",
    "\n",
    "# Call the Trainer\n",
    "trainer = Trainer(\n",
    "    model = model,                         \n",
    "    args = training_args,                  \n",
    "    train_dataset = train_dataset,         \n",
    "    eval_dataset = valid_dataset,          \n",
    "    compute_metrics = compute_metrics_for_regression,     \n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Call the summary\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f38ff535",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "execution": {
     "iopub.execute_input": "2023-01-13T23:52:10.904550Z",
     "iopub.status.busy": "2023-01-13T23:52:10.902397Z",
     "iopub.status.idle": "2023-01-13T23:53:23.328314Z",
     "shell.execute_reply": "2023-01-13T23:53:23.327339Z",
     "shell.execute_reply.started": "2023-01-13T23:52:10.904506Z"
    },
    "id": "9087d733",
    "outputId": "52698c03-4522-4531-9d34-21d8dd5e91e7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 18000\n",
      "  Batch size = 16\n"
     ]
    }
   ],
   "source": [
    "pred = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1af3cef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-13T23:53:23.330332Z",
     "iopub.status.busy": "2023-01-13T23:53:23.329733Z",
     "iopub.status.idle": "2023-01-13T23:53:23.335916Z",
     "shell.execute_reply": "2023-01-13T23:53:23.334964Z",
     "shell.execute_reply.started": "2023-01-13T23:53:23.330293Z"
    },
    "id": "o_u1-1j1qhSI"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "841dd278",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-01-13T23:53:23.337863Z",
     "iopub.status.busy": "2023-01-13T23:53:23.337316Z",
     "iopub.status.idle": "2023-01-13T23:53:23.360312Z",
     "shell.execute_reply": "2023-01-13T23:53:23.359154Z",
     "shell.execute_reply.started": "2023-01-13T23:53:23.337827Z"
    },
    "id": "IxNmId7Eq3Dk",
    "outputId": "76c84287-4138-4c75-a343-9b120accc400"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10715.423624403107"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(np.exp(y_test),np.exp(pd.DataFrame(pred[0])))**.5"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
