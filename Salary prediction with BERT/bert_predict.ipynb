{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"colab":{"provenance":[]},"accelerator":"GPU","gpuClass":"standard"},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install transformers\n!pip install nona","metadata":{"id":"n7h6P22uDuiI","execution":{"iopub.status.busy":"2023-01-13T20:58:37.762545Z","iopub.execute_input":"2023-01-13T20:58:37.763330Z","iopub.status.idle":"2023-01-13T20:58:48.219237Z","shell.execute_reply.started":"2023-01-13T20:58:37.763234Z","shell.execute_reply":"2023-01-13T20:58:48.217916Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: nona in /opt/conda/lib/python3.7/site-packages (0.0.2)\nRequirement already satisfied: tqdm>=4 in /opt/conda/lib/python3.7/site-packages (from nona) (4.64.0)\nRequirement already satisfied: numpy>=1 in /opt/conda/lib/python3.7/site-packages (from nona) (1.21.6)\nRequirement already satisfied: pandas>=1 in /opt/conda/lib/python3.7/site-packages (from nona) (1.3.5)\nRequirement already satisfied: scikit-learn>=1 in /opt/conda/lib/python3.7/site-packages (from nona) (1.0.2)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=1->nona) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=1->nona) (2022.1)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=1->nona) (1.0.1)\nRequirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=1->nona) (1.7.3)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=1->nona) (3.1.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas>=1->nona) (1.15.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2023-01-13T20:58:48.221999Z","iopub.execute_input":"2023-01-13T20:58:48.222439Z","iopub.status.idle":"2023-01-13T20:58:48.237327Z","shell.execute_reply.started":"2023-01-13T20:58:48.222391Z","shell.execute_reply":"2023-01-13T20:58:48.236142Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/df-salary/train_rev1.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch, gc, random\nfrom transformers.file_utils import is_tf_available, is_torch_available\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n# %load_ext memory_profiler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score, mean_squared_error, mean_absolute_error\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import Ridge\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.pipeline import make_pipeline\nimport re\nfrom nona.nona import nona","metadata":{"id":"c859605a","execution":{"iopub.status.busy":"2023-01-13T20:58:48.239359Z","iopub.execute_input":"2023-01-13T20:58:48.239746Z","iopub.status.idle":"2023-01-13T20:58:57.070667Z","shell.execute_reply.started":"2023-01-13T20:58:48.239710Z","shell.execute_reply":"2023-01-13T20:58:57.069542Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"gpu_info = !nvidia-smi\ngpu_info = '\\n'.join(gpu_info)\nif gpu_info.find('failed') >= 0:\n  print('Not connected to a GPU')\nelse:\n  print(gpu_info)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jiBzj-5tDnvO","outputId":"c9c47f4d-34fd-4c1d-85c5-984e8b904cab","execution":{"iopub.status.busy":"2023-01-13T20:58:57.074123Z","iopub.execute_input":"2023-01-13T20:58:57.075662Z","iopub.status.idle":"2023-01-13T20:58:57.157520Z","shell.execute_reply.started":"2023-01-13T20:58:57.075600Z","shell.execute_reply":"2023-01-13T20:58:57.156362Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Fri Jan 13 20:58:57 2023       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.82.01    Driver Version: 470.82.01    CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   38C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive')","metadata":{"id":"3Hs5LwoFFV-1","execution":{"iopub.status.busy":"2023-01-13T20:58:57.159160Z","iopub.execute_input":"2023-01-13T20:58:57.159534Z","iopub.status.idle":"2023-01-13T20:58:57.164502Z","shell.execute_reply.started":"2023-01-13T20:58:57.159493Z","shell.execute_reply":"2023-01-13T20:58:57.163434Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/df-salary/train_rev1.csv')\ndf = df.sample(200000,random_state=42)","metadata":{"id":"566eca83","execution":{"iopub.status.busy":"2023-01-13T20:58:57.165936Z","iopub.execute_input":"2023-01-13T20:58:57.166991Z","iopub.status.idle":"2023-01-13T20:59:06.862973Z","shell.execute_reply.started":"2023-01-13T20:58:57.166955Z","shell.execute_reply":"2023-01-13T20:59:06.861930Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df.drop('ContractType',axis=1,inplace=True)\n\ndef enc_with_na(df, column):\n    enc = OneHotEncoder(sparse=False, drop='first')\n    enc.fit(df[[column]].dropna())\n    \n    return enc,pd.DataFrame(enc.transform(df[[column]].dropna(\n    )), index=df.loc[df.loc[:, column].notna()].index, columns=enc.get_feature_names())","metadata":{"execution":{"iopub.status.busy":"2023-01-13T20:59:06.865042Z","iopub.execute_input":"2023-01-13T20:59:06.865390Z","iopub.status.idle":"2023-01-13T20:59:06.931362Z","shell.execute_reply.started":"2023-01-13T20:59:06.865361Z","shell.execute_reply":"2023-01-13T20:59:06.930376Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"ct_enc,ct_features = enc_with_na(df,'ContractTime')\ncat_enc,cat_features = enc_with_na(df,'Category')\n\ndf = df.drop(['ContractTime','Category'],axis=1).join([ct_features,\ncat_features])\n\nfeatures = df.drop(['Id','Title','FullDescription','LocationRaw','LocationNormalized','Company','SalaryRaw',\n                   'SalaryNormalized','SourceName'],axis=1)\n\nnona(data=features, algreg=make_pipeline(StandardScaler(with_mean=False), Ridge(\n    alpha=0.1)), algclass=RandomForestClassifier(max_depth=2, random_state=42))\n\ndf = df.join(pd.DataFrame(ct_enc.inverse_transform(pd.DataFrame(\n    features.loc[:, 'x0_permanent'])), index=df.index, columns=['ContractTime'])).drop(ct_enc.get_feature_names(), axis=1)\ndf = df.join(pd.DataFrame(cat_enc.inverse_transform(pd.DataFrame(\n    features.drop('x0_permanent',axis=1))), index=df.index, columns=['Category'])).drop(cat_enc.get_feature_names(), axis=1)\n\ndf[\"FullDescription\"] = df[\"FullDescription\"].str.replace(r'https?://[^\\s<>\"]+|www\\.[^\\s<>\"]+', \"\")\n\ndf.FullDescription = 'Contract time for this vacancy is '+ df.ContractTime+'. ' + df.FullDescription\ndf.FullDescription = 'The category for this job is '+ df.Category+'. ' + df.FullDescription","metadata":{"execution":{"iopub.status.busy":"2023-01-13T20:59:06.932934Z","iopub.execute_input":"2023-01-13T20:59:06.933578Z","iopub.status.idle":"2023-01-13T20:59:11.461301Z","shell.execute_reply.started":"2023-01-13T20:59:06.933535Z","shell.execute_reply":"2023-01-13T20:59:11.460237Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n  warnings.warn(msg, category=FutureWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n  warnings.warn(msg, category=FutureWarning)\n100%|██████████| 29/29 [00:00<00:00, 1196.26it/s]\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n  warnings.warn(msg, category=FutureWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n  warnings.warn(msg, category=FutureWarning)\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:18: FutureWarning: The default value of regex will change from True to False in a future version.\n","output_type":"stream"}]},{"cell_type":"code","source":"max_length = 128","metadata":{"id":"f0607805","execution":{"iopub.status.busy":"2023-01-13T20:59:11.462880Z","iopub.execute_input":"2023-01-13T20:59:11.463272Z","iopub.status.idle":"2023-01-13T20:59:11.471213Z","shell.execute_reply.started":"2023-01-13T20:59:11.463230Z","shell.execute_reply":"2023-01-13T20:59:11.470202Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"\n# Make data\nX = df.FullDescription\ny = np.log1p(df.SalaryNormalized+1)\n\n\n# Split Data\nX_train, X_valid, y_train, y_valid = train_test_split(X.tolist(), y, test_size=.1)\nX_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=.1)\n\n# Call the Tokenizer\ntokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n\n# Encode the text\ntrain_encodings = tokenizer(X_train, truncation=True, padding=True, max_length=max_length)\nvalid_encodings = tokenizer(X_valid, truncation=True, padding=True, max_length=max_length)\ntest_encodings = tokenizer(X_test, truncation=True, padding=True, max_length=max_length)\n\n\n\nclass MakeTorchData(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n        item[\"labels\"] = torch.tensor([self.labels[idx]])\n        item[\"labels\"] = float(item[\"labels\"])\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\n# convert our tokenized data into a torch Dataset\ntrain_dataset = MakeTorchData(train_encodings, y_train.ravel())\nvalid_dataset = MakeTorchData(valid_encodings, y_valid.ravel())\ntest_dataset = MakeTorchData(test_encodings, y_test.ravel())","metadata":{"id":"49c92e20","execution":{"iopub.status.busy":"2023-01-13T20:59:11.475096Z","iopub.execute_input":"2023-01-13T20:59:11.475696Z","iopub.status.idle":"2023-01-13T21:01:51.452147Z","shell.execute_reply.started":"2023-01-13T20:59:11.475642Z","shell.execute_reply":"2023-01-13T21:01:51.451121Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"\nmodel = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', \n                                                           num_labels = 1).to(\"cuda\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"70ad6a6b","outputId":"43424b59-9044-432c-85c6-d26222c400fd","execution":{"iopub.status.busy":"2023-01-13T21:01:51.453669Z","iopub.execute_input":"2023-01-13T21:01:51.454340Z","iopub.status.idle":"2023-01-13T21:02:01.383115Z","shell.execute_reply.started":"2023-01-13T21:01:51.454299Z","shell.execute_reply":"2023-01-13T21:02:01.378806Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"def compute_metrics_for_regression(eval_pred):\n    logits, labels = eval_pred\n    labels = labels.reshape(-1, 1)\n\n    mse = mean_squared_error(labels, logits)\n    rmse = mean_squared_error(labels, logits, squared=False)\n    mae = mean_absolute_error(labels, logits)\n    r2 = r2_score(labels, logits)\n    smape = 1/len(labels) * np.sum(2 * np.abs(logits-labels) / (np.abs(labels) + np.abs(logits))*100)\n\n    return {\"mse\": mse, \"rmse\": rmse, \"mae\": mae, \"r2\": r2, \"smape\": smape}","metadata":{"id":"5623a753","execution":{"iopub.status.busy":"2023-01-13T21:02:01.388586Z","iopub.execute_input":"2023-01-13T21:02:01.389343Z","iopub.status.idle":"2023-01-13T21:02:01.398062Z","shell.execute_reply.started":"2023-01-13T21:02:01.389301Z","shell.execute_reply":"2023-01-13T21:02:01.397088Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"num_epochs = 5","metadata":{"id":"cfac0b69","execution":{"iopub.status.busy":"2023-01-13T21:02:01.399615Z","iopub.execute_input":"2023-01-13T21:02:01.400151Z","iopub.status.idle":"2023-01-13T21:02:01.415491Z","shell.execute_reply.started":"2023-01-13T21:02:01.400108Z","shell.execute_reply":"2023-01-13T21:02:01.414488Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"os.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"execution":{"iopub.status.busy":"2023-01-13T21:02:01.416949Z","iopub.execute_input":"2023-01-13T21:02:01.417357Z","iopub.status.idle":"2023-01-13T21:02:01.426459Z","shell.execute_reply.started":"2023-01-13T21:02:01.417322Z","shell.execute_reply":"2023-01-13T21:02:01.425431Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"\n# Specifiy the arguments for the trainer  \ntraining_args = TrainingArguments(\n    output_dir ='D:/',          \n    num_train_epochs = num_epochs,     \n    per_device_train_batch_size = 32,   \n    per_device_eval_batch_size = 16,   \n    weight_decay = 0.01,               \n    learning_rate = 2e-5,\n    logging_dir = './logs',            \n    save_total_limit = 10,\n    load_best_model_at_end = True,     \n    metric_for_best_model = 'rmse',    \n    evaluation_strategy = \"epoch\",\n    save_strategy = \"epoch\",\n    optim=\"adamw_torch\"\n) \n\n# Call the Trainer\ntrainer = Trainer(\n    model = model,                         \n    args = training_args,                  \n    train_dataset = train_dataset,         \n    eval_dataset = valid_dataset,          \n    compute_metrics = compute_metrics_for_regression,     \n)\n\n# Train the model\ntrainer.train()\n\n# Call the summary\ntrainer.evaluate()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"babe9eed","outputId":"d00adb81-190d-4ca1-9833-df0d29bef78c","execution":{"iopub.status.busy":"2023-01-13T21:02:01.427814Z","iopub.execute_input":"2023-01-13T21:02:01.428256Z","iopub.status.idle":"2023-01-13T23:52:10.897895Z","shell.execute_reply.started":"2023-01-13T21:02:01.428218Z","shell.execute_reply":"2023-01-13T23:52:10.896866Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n***** Running training *****\n  Num examples = 162000\n  Num Epochs = 5\n  Instantaneous batch size per device = 32\n  Total train batch size (w. parallel, distributed & accumulation) = 32\n  Gradient Accumulation steps = 1\n  Total optimization steps = 25315\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='25315' max='25315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [25315/25315 2:48:49, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Mse</th>\n      <th>Rmse</th>\n      <th>Mae</th>\n      <th>R2</th>\n      <th>Smape</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.093000</td>\n      <td>0.083277</td>\n      <td>0.083277</td>\n      <td>0.288577</td>\n      <td>0.220120</td>\n      <td>0.653671</td>\n      <td>2.129631</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.077200</td>\n      <td>0.062945</td>\n      <td>0.062945</td>\n      <td>0.250888</td>\n      <td>0.184665</td>\n      <td>0.738227</td>\n      <td>1.789336</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.063400</td>\n      <td>0.058853</td>\n      <td>0.058853</td>\n      <td>0.242597</td>\n      <td>0.174391</td>\n      <td>0.755243</td>\n      <td>1.686801</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.055100</td>\n      <td>0.070401</td>\n      <td>0.070401</td>\n      <td>0.265331</td>\n      <td>0.202370</td>\n      <td>0.707220</td>\n      <td>1.959186</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.051000</td>\n      <td>0.059627</td>\n      <td>0.059627</td>\n      <td>0.244186</td>\n      <td>0.177942</td>\n      <td>0.752026</td>\n      <td>1.720433</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"***** Running Evaluation *****\n  Num examples = 20000\n  Batch size = 16\nSaving model checkpoint to D:/checkpoint-5063\nConfiguration saved in D:/checkpoint-5063/config.json\nModel weights saved in D:/checkpoint-5063/pytorch_model.bin\n***** Running Evaluation *****\n  Num examples = 20000\n  Batch size = 16\nSaving model checkpoint to D:/checkpoint-10126\nConfiguration saved in D:/checkpoint-10126/config.json\nModel weights saved in D:/checkpoint-10126/pytorch_model.bin\n***** Running Evaluation *****\n  Num examples = 20000\n  Batch size = 16\nSaving model checkpoint to D:/checkpoint-15189\nConfiguration saved in D:/checkpoint-15189/config.json\nModel weights saved in D:/checkpoint-15189/pytorch_model.bin\n***** Running Evaluation *****\n  Num examples = 20000\n  Batch size = 16\nSaving model checkpoint to D:/checkpoint-20252\nConfiguration saved in D:/checkpoint-20252/config.json\nModel weights saved in D:/checkpoint-20252/pytorch_model.bin\n***** Running Evaluation *****\n  Num examples = 20000\n  Batch size = 16\nSaving model checkpoint to D:/checkpoint-25315\nConfiguration saved in D:/checkpoint-25315/config.json\nModel weights saved in D:/checkpoint-25315/pytorch_model.bin\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\nLoading best model from D:/checkpoint-5063 (score: 0.2885771691799164).\n***** Running Evaluation *****\n  Num examples = 20000\n  Batch size = 16\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2375' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1250/1250 02:30]\n    </div>\n    "},"metadata":{}},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.08327678591012955,\n 'eval_mse': 0.08327678591012955,\n 'eval_rmse': 0.2885771691799164,\n 'eval_mae': 0.2201199233531952,\n 'eval_r2': 0.6536712649745798,\n 'eval_smape': 2.1296306640625002,\n 'eval_runtime': 78.1274,\n 'eval_samples_per_second': 255.992,\n 'eval_steps_per_second': 16.0,\n 'epoch': 5.0}"},"metadata":{}}]},{"cell_type":"code","source":"pred = trainer.predict(test_dataset)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"9087d733","outputId":"52698c03-4522-4531-9d34-21d8dd5e91e7","execution":{"iopub.status.busy":"2023-01-13T23:52:10.902397Z","iopub.execute_input":"2023-01-13T23:52:10.904550Z","iopub.status.idle":"2023-01-13T23:53:23.328314Z","shell.execute_reply.started":"2023-01-13T23:52:10.904506Z","shell.execute_reply":"2023-01-13T23:53:23.327339Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"***** Running Prediction *****\n  Num examples = 18000\n  Batch size = 16\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error","metadata":{"id":"o_u1-1j1qhSI","execution":{"iopub.status.busy":"2023-01-13T23:53:23.329733Z","iopub.execute_input":"2023-01-13T23:53:23.330332Z","iopub.status.idle":"2023-01-13T23:53:23.335916Z","shell.execute_reply.started":"2023-01-13T23:53:23.330293Z","shell.execute_reply":"2023-01-13T23:53:23.334964Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"mean_squared_error(np.exp(y_test),np.exp(pd.DataFrame(pred[0])))**.5","metadata":{"id":"IxNmId7Eq3Dk","outputId":"76c84287-4138-4c75-a343-9b120accc400","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2023-01-13T23:53:23.337316Z","iopub.execute_input":"2023-01-13T23:53:23.337863Z","iopub.status.idle":"2023-01-13T23:53:23.360312Z","shell.execute_reply.started":"2023-01-13T23:53:23.337827Z","shell.execute_reply":"2023-01-13T23:53:23.359154Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"10715.423624403107"},"metadata":{}}]}]}